Fix these errors:

(no newline)
tiian@ubuntu1404-64:~$ cat /tmp/flom-vfs/status/lockers/4/holders/3/peer_name 
192.168.123.154/58218tiian@ubuntu1404-64:~$

(Input/output error) in ls -la
tiian@ubuntu1404-64:~$ ls -la /tmp/flom-vfs/status/incubator/2/
ls: /tmp/flom-vfs/status/incubator/2/: Input/output error
ls: /tmp/flom-vfs/status/incubator/2/.: Input/output error
ls: /tmp/flom-vfs/status/incubator/2/..: Input/output error
ls: /tmp/flom-vfs/status/incubator/2/peer_name: Input/output error
ls: /tmp/flom-vfs/status/incubator/2/resource_name: Input/output error
ls: /tmp/flom-vfs/status/incubator/2/resource_type: Input/output error
total 0
dr-xr-x--- 2 tiian tiian  0 dic 31 15:17 .
dr-xr-x--- 2 tiian tiian  0 dic 31 15:17 ..
-r--r----- 1 tiian tiian 21 dic 31 15:17 peer_name
-r--r----- 1 tiian tiian  7 dic 31 15:17 resource_name
-r--r----- 1 tiian tiian  8 dic 31 15:17 resource_type


To improve the quantity of data available in the VFS it's required to perform
several changes that might be taken into consideration in the future if real
interest will emerge.
Put in every
flom_resource_*.c
a new callback function that returns a piece of RAM VFS with the specific
info of the resource.
For numeric, for example, it will be: 
total_quantity
locked_quantity
The main idea is:
in flom_locker.c line 90, inside flom_vfs_ram_tree_add_locker the callback
function on the specific resource will be called and it will give back a list
of files/dirs to put inside the status/lockers/UID dir; brothers and sisters
of "resource_name" and "resource_type". In theory, even them should be part of
the retrieved list of files/dirs.
If the resource must create a dir with files inside it, that will be definitively become more and more complicated...





Possible ideas for future developments, if useful: 

implement stack trace feature as implemented by LIXA project

introduce a supplementary module build for Perl and Python to avoid installation before "make check" (verify other bindings like Java too...)

implement a loop for connect/bind if bind returns an error: this should help
to reduce the race condition between a closing daemon and a starting client.
See this thread: https://github.com/tiian/flom/issues/3

Other ideas.....

"object" resources with a state, a memory area, managed by FLoM to transform it in a "state manager" other than a "lock manager"; for flom client, the object will be dumped/restored to/from file

"vector" resources with an associative array of memory areas, managed by FLoM (evolution of "object"; for flom client, the vector will be dumped/restored to/from a zip file or a directory

RESTful interface implemented using Mongoose (?)

replace poll custom based implementation with libevent... (is it interesting?)

put inside function flom_accept_loop_chklockers a check if the thread associated to the locker is really active; if the thread leaved (due to an error), make a clean-up phase. This avoid a daemon crash after a thread terminated with an error, but listener thread has a "locker object" already active

implement FIFO, LIFO, FIRST FIT (for numerical resources) lock allocation policies
